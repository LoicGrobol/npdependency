word_embedding_size  : [100,200]
tag_embedding_size   : [100,200]
encoder_dropout : [0.5]
mlp_input           : 400 
mlp_arc_hidden  : [300,400,500] 
mlp_lab_hidden  : 100 
mlp_dropout       : [0.3,0.5]
word_dropout     : [0.3,0.5]
batch_size          :  128
epochs                : 70
lexer                   : 'fasttext'
device                 : 'cuda:0'
output_path        : 'ft_lexer/preds' 
